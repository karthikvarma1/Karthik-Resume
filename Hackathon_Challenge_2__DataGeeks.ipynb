{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hackathon Challenge 2_ DataGeeks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikvarma1/Karthik-Resume/blob/gh-pages/Hackathon_Challenge_2__DataGeeks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrZD-XgUSquc"
      },
      "source": [
        "**DATA GEEKS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmR_VjOZSVx7"
      },
      "source": [
        "1) Vinay Kumar Reddy Gaddam \n",
        "\n",
        "\n",
        "2) Shamshuddin Dudekula\n",
        "\n",
        "\n",
        "3) Karthik Varma Keerthipati\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwQw9gQjSej0"
      },
      "source": [
        "**Challenge2 - non-STEM assessment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mqIl0m6TNUi"
      },
      "source": [
        "**OBJECTIVE**  : To prepare a model to grade non-STEM examinations using LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHkvqd5ESXX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9c092b-3efd-423c-d31c-8e0e1e93f874"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w78R2Q6wSUuw"
      },
      "source": [
        "**Imported Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VJWpvSh_OPh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from gensim.models import Word2Vec\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "from keras.models import Sequential, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import cohen_kappa_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k56KN5s5UDT-"
      },
      "source": [
        "**Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhURxpSq6jtx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "3a4f4df5-77f0-4df1-e283-24d83c0db204"
      },
      "source": [
        "\n",
        "df = pd.read_csv(\"/data_essay.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d320f58f89fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/data_essay.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data_essay.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84jTaEz6AH52",
        "outputId": "1192c982-fc7b-44f1-d953-aad68142c0e5"
      },
      "source": [
        "df['essay_set'].unique()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5, 6, 7, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP9WWzZ-_Ri5"
      },
      "source": [
        "q1= df.loc[df['essay_set'] == 1]\n",
        "q2= df.loc[df['essay_set'] == 2]\n",
        "q3= df.loc[df['essay_set'] == 3]\n",
        "q4= df.loc[df['essay_set'] == 4]\n",
        "q5= df.loc[df['essay_set'] == 5]\n",
        "q6= df.loc[df['essay_set'] == 6]\n",
        "q7= df.loc[df['essay_set'] == 7]\n",
        "q8= df.loc[df['essay_set'] == 8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1LBUp1CAf1s",
        "outputId": "7c615461-ab1c-463b-babd-b21e323c8999"
      },
      "source": [
        "print(\"Scoring range of q1\",sorted(q1.score.unique()))\n",
        "print(\"Scoring range of q2\",sorted(q2.score.unique()))\n",
        "print(\"Scoring range of q3\",sorted(q3.score.unique()))\n",
        "print(\"Scoring range of q4\",sorted(q4.score.unique()))\n",
        "print(\"Scoring range of q5\",sorted(q5.score.unique()))\n",
        "print(\"Scoring range of q6\",sorted(q6.score.unique()))\n",
        "print(\"Scoring range of q7\",sorted(q7.score.unique()))\n",
        "print(\"Scoring range of q8\",sorted(q8.score.unique()))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scoring range of q1 [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
            "Scoring range of q2 [1, 2, 3, 4, 5, 6]\n",
            "Scoring range of q3 [0, 1, 2, 3]\n",
            "Scoring range of q4 [0, 1, 2, 3]\n",
            "Scoring range of q5 [0, 1, 2, 3, 4]\n",
            "Scoring range of q6 [0, 1, 2, 3, 4]\n",
            "Scoring range of q7 [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
            "Scoring range of q8 [10, 15, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 55, 60]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUXF5uAGCT3r"
      },
      "source": [
        "##**Data Processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl9tDry6Jg2S"
      },
      "source": [
        "As we know data processing steps include tokenizing, lower casing, stop words, stemming.\n",
        "We have performed required steps accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKQ4FOwnCSuW"
      },
      "source": [
        "q1t = q1['essay']\n",
        "q2t = q2['essay']\n",
        "q3t = q3['essay']\n",
        "q4t = q4['essay']\n",
        "q5t = q5['essay']\n",
        "q6t = q6['essay']\n",
        "q7t = q7['essay']\n",
        "q8t = q8['essay']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvSAutElnm_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e3fd990-e95c-4df4-b3d2-9d6bce2cf932"
      },
      "source": [
        "\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "new = set(['well', 'using', 'us', 'recommend', 'use', ])\n",
        "stop_words =stop_words.union(new)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdT3QNj6qpji"
      },
      "source": [
        "\n",
        "def preprocess(df):\n",
        "  text = []\n",
        "# tqdm is for printing the status bar\n",
        "  for sentance in tqdm(df.values):  \n",
        "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
        "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
        "    sentance = decontracted(sentance)\n",
        "    sentance = re.sub('\\W+','', sentance)\n",
        "    #sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
        "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
        "    # https://gist.github.com/sebleier/554280\n",
        "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stop_words)\n",
        "    text.append(sentance.strip())\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LqOR9GcF8Z1",
        "outputId": "012b2530-1aef-4638-e9bb-801bfc3a41e3"
      },
      "source": [
        "p1 =  preprocess(q1t)\n",
        "p2 =  preprocess(q2t)\n",
        "p3 =  preprocess(q3t)\n",
        "p4 =  preprocess(q4t)\n",
        "p5 =  preprocess(q5t)\n",
        "p6 =  preprocess(q6t)\n",
        "p7 =  preprocess(q7t)\n",
        "p8 =  preprocess(q8t)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1783/1783 [00:00<00:00, 2655.69it/s]\n",
            "100%|██████████| 3600/3600 [00:01<00:00, 2604.85it/s]\n",
            "100%|██████████| 1726/1726 [00:00<00:00, 4182.63it/s]\n",
            "100%|██████████| 1770/1770 [00:00<00:00, 4205.52it/s]\n",
            "100%|██████████| 1805/1805 [00:00<00:00, 4036.04it/s]\n",
            "100%|██████████| 1800/1800 [00:00<00:00, 3797.46it/s]\n",
            "100%|██████████| 1569/1569 [00:00<00:00, 3667.76it/s]\n",
            "100%|██████████| 723/723 [00:00<00:00, 2098.13it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idydbGTlHHgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5c752a-4876-4e58-8229-d45549e6ba5c"
      },
      "source": [
        "q1[\"P_essay\"] = p1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgMY0EhMJ2hr",
        "outputId": "51ddc631-c11b-487a-81b5-97d2a8809608"
      },
      "source": [
        "q2[\"P_essay\"] = p2\n",
        "q3[\"P_essay\"] = p3\n",
        "q4[\"P_essay\"] = p4\n",
        "q5[\"P_essay\"] = p5\n",
        "q6[\"P_essay\"] = p6\n",
        "q7[\"P_essay\"] = p7\n",
        "q8[\"P_essay\"] = p8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PPZuzV4LOCL"
      },
      "source": [
        "X= q1\n",
        "y = X.score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naXYxVSrUwER"
      },
      "source": [
        "##**Data Modelling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IISGkq2LLzn"
      },
      "source": [
        "For tokenization we have used feature vector , as it is a collection of text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG1pfKC9PBQ0"
      },
      "source": [
        "\n",
        "def makeFeatureVec(words, model, num_features):\n",
        "    \"\"\"Make Feature Vector from the words list of an Essay.\"\"\"\n",
        "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
        "    num_words = 0.\n",
        "    index2word_set = set(model.wv.index2word)\n",
        "    for word in words:\n",
        "        if word in index2word_set:\n",
        "            num_words += 1\n",
        "            featureVec = np.add(featureVec,model[word])        \n",
        "    featureVec = np.divide(featureVec,num_words)\n",
        "    return featureVec\n",
        "\n",
        "def getAvgFeatureVecs(essays, model, num_features):\n",
        "    \"\"\"Main function to generate the word vectors for word2vec model.\"\"\"\n",
        "    counter = 0\n",
        "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
        "    for essay in essays:\n",
        "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
        "        counter = counter + 1\n",
        "    return essayFeatureVecs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvlZa2rGU1nM"
      },
      "source": [
        "Long Short-Term Memory (LSTM) networks are a type of recurrent neural network capable of learning order dependence in sequence prediction problems. This is a behavior required in complex problem domains like machine translation, speech recognition, and more. LSTMs are a complex area of deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRoFhJZVVJmI"
      },
      "source": [
        "Here we have used LSTM to get our required result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwWOeAs0PDbD"
      },
      "source": [
        "\n",
        "\n",
        "def get_model(n):\n",
        "    \"\"\"Define the model.\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "    model.add(Dense(n, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy','mae'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxMCQKFPOny7"
      },
      "source": [
        "n = len(q1.score.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTa0ioyLKK4M",
        "outputId": "9b38d3e4-5edd-40a5-b9c7-16c30f3ba079"
      },
      "source": [
        "\n",
        "cv = KFold(n_splits = 5, shuffle = True)\n",
        "results = []\n",
        "y_pred_list = []\n",
        "count = 1\n",
        "for traincv, testcv in cv.split(X):\n",
        "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
        "    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
        "    train_essays = list(X_train['P_essay'].values)\n",
        "    test_essays = list(X_test['P_essay'].values)\n",
        "    # Initializing variables for word2vec model.\n",
        "    num_features = 300 \n",
        "    min_word_count = 40\n",
        "    num_workers = 4\n",
        "    context = 10\n",
        "    downsampling = 1e-3\n",
        "\n",
        "    print(\"Training Word2Vec Model...\")\n",
        "    model = Word2Vec(train_essays, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
        "\n",
        "    model.init_sims(replace=True)\n",
        "    model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
        "    trainDataVecs = getAvgFeatureVecs(train_essays, model, num_features)\n",
        "    testDataVecs = getAvgFeatureVecs(test_essays, model, num_features )\n",
        "    \n",
        "    trainDataVecs = np.array(trainDataVecs)\n",
        "    testDataVecs = np.array(testDataVecs)\n",
        "    # Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
        "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
        "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "    \n",
        "    lstm_model = get_model(n)\n",
        "    lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=50)\n",
        "    #lstm_model.load_weights('./model_weights/final_lstm.h5')\n",
        "    y_pred = lstm_model.predict(testDataVecs)\n",
        "    \n",
        "    # Save any one of the 5 models.\n",
        "    if count == 5:\n",
        "         lstm_model.save('./final_lstm.h5')\n",
        "    \n",
        "    # Round y_pred to the nearest integer.\n",
        "    y_pred = np.around(y_pred)\n",
        "    \n",
        "    # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
        "    result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    acc = accuracy_score(y_test.values,y_pred)\n",
        "    print(\"acc Score: {}\".format(acc))\n",
        "    print(\"Kappa Score: {}\".format(result))\n",
        "    results.append(result)\n",
        "\n",
        "    count += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "Training Word2Vec Model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 25s 16ms/step - loss: 66.7215 - accuracy: 0.0000e+00 - mae: 7.9935\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 17.7606 - accuracy: 0.0000e+00 - mae: 3.7882\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.9102 - accuracy: 0.0000e+00 - mae: 1.5383\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.6027 - accuracy: 0.0000e+00 - mae: 1.4790\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.4115 - accuracy: 0.0000e+00 - mae: 1.4591\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.8989 - accuracy: 0.0000e+00 - mae: 1.5285\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.5644 - accuracy: 0.0000e+00 - mae: 1.4763\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.7781 - accuracy: 0.0000e+00 - mae: 1.5050\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.9147 - accuracy: 0.0000e+00 - mae: 1.5027\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.7646 - accuracy: 0.0000e+00 - mae: 1.5120\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.7876 - accuracy: 0.0000e+00 - mae: 1.5051\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.6229 - accuracy: 0.0000e+00 - mae: 1.4722\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.7537 - accuracy: 0.0000e+00 - mae: 1.4898\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4321 - accuracy: 0.0000e+00 - mae: 1.4470\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.2838 - accuracy: 0.0000e+00 - mae: 1.4073\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.3504 - accuracy: 0.0000e+00 - mae: 1.4559\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.5263 - accuracy: 0.0000e+00 - mae: 1.4541\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.4068 - accuracy: 0.0000e+00 - mae: 1.4279\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.6203 - accuracy: 0.0000e+00 - mae: 1.4648\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3650 - accuracy: 0.0000e+00 - mae: 1.4006\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2752 - accuracy: 0.0000e+00 - mae: 1.4009\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.6143 - accuracy: 0.0000e+00 - mae: 1.4876\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3904 - accuracy: 0.0000e+00 - mae: 1.4026\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2508 - accuracy: 0.0000e+00 - mae: 1.4053\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.3168 - accuracy: 0.0000e+00 - mae: 1.4170\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.0705 - accuracy: 0.0000e+00 - mae: 1.3407\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.3993 - accuracy: 0.0000e+00 - mae: 1.4139\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.2603 - accuracy: 0.0000e+00 - mae: 1.4179\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.3330 - accuracy: 0.0000e+00 - mae: 1.4045\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.0841 - accuracy: 0.0000e+00 - mae: 1.3601\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2916 - accuracy: 0.0000e+00 - mae: 1.4014\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.4678 - accuracy: 0.0000e+00 - mae: 1.4756\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.3807 - accuracy: 0.0000e+00 - mae: 1.4052\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.0675 - accuracy: 0.0000e+00 - mae: 1.3578\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3705 - accuracy: 0.0000e+00 - mae: 1.4159\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3152 - accuracy: 0.0000e+00 - mae: 1.4266\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.6433 - accuracy: 0.0000e+00 - mae: 1.4764\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2814 - accuracy: 0.0000e+00 - mae: 1.4098\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1737 - accuracy: 0.0000e+00 - mae: 1.3789\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.2829 - accuracy: 0.0000e+00 - mae: 1.3845\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1920 - accuracy: 0.0000e+00 - mae: 1.3622\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2302 - accuracy: 0.0000e+00 - mae: 1.4122\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.1024 - accuracy: 0.0000e+00 - mae: 1.3652\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2328 - accuracy: 0.0000e+00 - mae: 1.3885\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4171 - accuracy: 0.0000e+00 - mae: 1.4577\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.6170 - accuracy: 0.0000e+00 - mae: 1.4642\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.3701 - accuracy: 0.0000e+00 - mae: 1.3881\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.0190 - accuracy: 0.0000e+00 - mae: 1.3448\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.4082 - accuracy: 0.0000e+00 - mae: 1.4273\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1060 - accuracy: 0.0000e+00 - mae: 1.3474\n",
            "acc Score: 0.3641456582633053\n",
            "Kappa Score: 0.18895553610690108\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "Training Word2Vec Model...\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 6s 15ms/step - loss: 65.7295 - accuracy: 0.0000e+00 - mae: 7.9239\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 14.8329 - accuracy: 0.0000e+00 - mae: 3.4301\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.9038 - accuracy: 0.0000e+00 - mae: 1.5395\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.6239 - accuracy: 0.0000e+00 - mae: 1.4861\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.7970 - accuracy: 0.0000e+00 - mae: 1.5235\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.7603 - accuracy: 0.0000e+00 - mae: 1.5147\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2644 - accuracy: 0.0000e+00 - mae: 1.3925\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.6465 - accuracy: 0.0000e+00 - mae: 1.5115\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 3.5297 - accuracy: 0.0000e+00 - mae: 1.4519\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.6148 - accuracy: 0.0000e+00 - mae: 1.4859\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.5339 - accuracy: 0.0000e+00 - mae: 1.4847\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.5558 - accuracy: 0.0000e+00 - mae: 1.4678\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4838 - accuracy: 0.0000e+00 - mae: 1.4769\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.1511 - accuracy: 0.0000e+00 - mae: 1.4051\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.6276 - accuracy: 0.0000e+00 - mae: 1.4855\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4536 - accuracy: 0.0000e+00 - mae: 1.4677\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3111 - accuracy: 0.0000e+00 - mae: 1.4141\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.8548 - accuracy: 0.0000e+00 - mae: 1.5234\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.4174 - accuracy: 0.0000e+00 - mae: 1.4498\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2329 - accuracy: 0.0000e+00 - mae: 1.4104\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.3366 - accuracy: 0.0000e+00 - mae: 1.4271\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.4321 - accuracy: 0.0000e+00 - mae: 1.4475\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4358 - accuracy: 0.0000e+00 - mae: 1.4256\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1968 - accuracy: 0.0000e+00 - mae: 1.3986\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.1559 - accuracy: 0.0000e+00 - mae: 1.3484\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1887 - accuracy: 0.0000e+00 - mae: 1.3972\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.0808 - accuracy: 0.0000e+00 - mae: 1.3719\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2450 - accuracy: 0.0000e+00 - mae: 1.3992\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.2295 - accuracy: 0.0000e+00 - mae: 1.3998\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3225 - accuracy: 0.0000e+00 - mae: 1.4262\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 2.9937 - accuracy: 0.0000e+00 - mae: 1.3561\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3402 - accuracy: 0.0000e+00 - mae: 1.4466\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.0732 - accuracy: 0.0000e+00 - mae: 1.3801\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.0314 - accuracy: 0.0000e+00 - mae: 1.3842\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.0479 - accuracy: 0.0000e+00 - mae: 1.3622\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.2549 - accuracy: 0.0000e+00 - mae: 1.4113\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2290 - accuracy: 0.0000e+00 - mae: 1.4029\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.1528 - accuracy: 0.0000e+00 - mae: 1.3845\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2940 - accuracy: 0.0000e+00 - mae: 1.4147\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.2540 - accuracy: 0.0000e+00 - mae: 1.3778\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2245 - accuracy: 0.0000e+00 - mae: 1.4103\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 2.9736 - accuracy: 0.0000e+00 - mae: 1.3381\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3733 - accuracy: 0.0000e+00 - mae: 1.4386\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.0521 - accuracy: 0.0000e+00 - mae: 1.3777\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3865 - accuracy: 0.0000e+00 - mae: 1.4181\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.2622 - accuracy: 0.0000e+00 - mae: 1.3954\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1455 - accuracy: 0.0000e+00 - mae: 1.3969\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3913 - accuracy: 0.0000e+00 - mae: 1.3867\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1672 - accuracy: 0.0000e+00 - mae: 1.3581\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 2.9894 - accuracy: 0.0000e+00 - mae: 1.3606\n",
            "acc Score: 0.27170868347338933\n",
            "Kappa Score: 0.06099069542300872\n",
            "\n",
            "--------Fold 3--------\n",
            "\n",
            "Training Word2Vec Model...\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 6s 17ms/step - loss: 68.5866 - accuracy: 0.0000e+00 - mae: 8.1193\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 20.7472 - accuracy: 0.0000e+00 - mae: 4.1652\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 4.5552 - accuracy: 0.0000e+00 - mae: 1.6812\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.6886 - accuracy: 0.0000e+00 - mae: 1.4932\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.8417 - accuracy: 0.0000e+00 - mae: 1.4949\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.5962 - accuracy: 0.0000e+00 - mae: 1.4469\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.4026 - accuracy: 0.0000e+00 - mae: 1.4264\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.8025 - accuracy: 0.0000e+00 - mae: 1.5353\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.6157 - accuracy: 0.0000e+00 - mae: 1.4666\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.9915 - accuracy: 0.0000e+00 - mae: 1.5438\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.5766 - accuracy: 0.0000e+00 - mae: 1.4823\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.5030 - accuracy: 0.0000e+00 - mae: 1.4533\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3653 - accuracy: 0.0000e+00 - mae: 1.4323\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3321 - accuracy: 0.0000e+00 - mae: 1.4322\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.5406 - accuracy: 0.0000e+00 - mae: 1.4429\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2332 - accuracy: 0.0000e+00 - mae: 1.3880\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.4457 - accuracy: 0.0000e+00 - mae: 1.4503\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.7141 - accuracy: 0.0000e+00 - mae: 1.4636\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2734 - accuracy: 0.0000e+00 - mae: 1.4267\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2373 - accuracy: 0.0000e+00 - mae: 1.3876\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.5049 - accuracy: 0.0000e+00 - mae: 1.4421\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2148 - accuracy: 0.0000e+00 - mae: 1.4077\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2418 - accuracy: 0.0000e+00 - mae: 1.3914\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.6295 - accuracy: 0.0000e+00 - mae: 1.4636\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2237 - accuracy: 0.0000e+00 - mae: 1.3929\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2562 - accuracy: 0.0000e+00 - mae: 1.3898\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.1160 - accuracy: 0.0000e+00 - mae: 1.3637\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.0125 - accuracy: 0.0000e+00 - mae: 1.3204\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3363 - accuracy: 0.0000e+00 - mae: 1.4075\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1828 - accuracy: 0.0000e+00 - mae: 1.3842\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1604 - accuracy: 0.0000e+00 - mae: 1.3689\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2945 - accuracy: 0.0000e+00 - mae: 1.4061\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 2.9728 - accuracy: 0.0000e+00 - mae: 1.3395\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2580 - accuracy: 0.0000e+00 - mae: 1.3826\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2423 - accuracy: 0.0000e+00 - mae: 1.4120\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.2509 - accuracy: 0.0000e+00 - mae: 1.4088\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1694 - accuracy: 0.0000e+00 - mae: 1.3756\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2173 - accuracy: 0.0000e+00 - mae: 1.3707\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1101 - accuracy: 0.0000e+00 - mae: 1.3807\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3250 - accuracy: 0.0000e+00 - mae: 1.4269\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3830 - accuracy: 0.0000e+00 - mae: 1.4518\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1450 - accuracy: 0.0000e+00 - mae: 1.3820\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 2.9468 - accuracy: 0.0000e+00 - mae: 1.3449\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 2.8577 - accuracy: 0.0000e+00 - mae: 1.3155\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.2709 - accuracy: 0.0000e+00 - mae: 1.4108\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 2.9607 - accuracy: 0.0000e+00 - mae: 1.3533\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 2.9970 - accuracy: 0.0000e+00 - mae: 1.3377\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.2480 - accuracy: 0.0000e+00 - mae: 1.4094\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1737 - accuracy: 0.0000e+00 - mae: 1.3901\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.2231 - accuracy: 0.0000e+00 - mae: 1.4171\n",
            "acc Score: 0.3473389355742297\n",
            "Kappa Score: 0.18257700446743474\n",
            "\n",
            "--------Fold 4--------\n",
            "\n",
            "Training Word2Vec Model...\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_6 (LSTM)                (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 6s 16ms/step - loss: 68.2832 - accuracy: 0.0000e+00 - mae: 8.0870\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 19.6440 - accuracy: 0.0000e+00 - mae: 4.0358\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 4.3283 - accuracy: 0.0000e+00 - mae: 1.6586\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 3.5749 - accuracy: 0.0000e+00 - mae: 1.5015\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.5740 - accuracy: 0.0000e+00 - mae: 1.4814\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4934 - accuracy: 0.0000e+00 - mae: 1.4435\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.7816 - accuracy: 0.0000e+00 - mae: 1.5138\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4486 - accuracy: 0.0000e+00 - mae: 1.4487\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3513 - accuracy: 0.0000e+00 - mae: 1.4402\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.4131 - accuracy: 0.0000e+00 - mae: 1.4540\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4415 - accuracy: 0.0000e+00 - mae: 1.4649\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3047 - accuracy: 0.0000e+00 - mae: 1.4255\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.4240 - accuracy: 0.0000e+00 - mae: 1.4401\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.5229 - accuracy: 0.0000e+00 - mae: 1.4587\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4480 - accuracy: 0.0000e+00 - mae: 1.4403\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4881 - accuracy: 0.0000e+00 - mae: 1.4513\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4256 - accuracy: 0.0000e+00 - mae: 1.4467\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4413 - accuracy: 0.0000e+00 - mae: 1.4463\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.5436 - accuracy: 0.0000e+00 - mae: 1.4822\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4816 - accuracy: 0.0000e+00 - mae: 1.4506\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.3764 - accuracy: 0.0000e+00 - mae: 1.4413\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4769 - accuracy: 0.0000e+00 - mae: 1.4326\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3181 - accuracy: 0.0000e+00 - mae: 1.4334\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.3304 - accuracy: 0.0000e+00 - mae: 1.4300\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2925 - accuracy: 0.0000e+00 - mae: 1.4198\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3452 - accuracy: 0.0000e+00 - mae: 1.4293\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2117 - accuracy: 0.0000e+00 - mae: 1.3948\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2891 - accuracy: 0.0000e+00 - mae: 1.3991\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2743 - accuracy: 0.0000e+00 - mae: 1.3984\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.5382 - accuracy: 0.0000e+00 - mae: 1.4616\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3783 - accuracy: 0.0000e+00 - mae: 1.4312\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2605 - accuracy: 0.0000e+00 - mae: 1.4115\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2079 - accuracy: 0.0000e+00 - mae: 1.3961\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3314 - accuracy: 0.0000e+00 - mae: 1.4381\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3462 - accuracy: 0.0000e+00 - mae: 1.4325\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.5518 - accuracy: 0.0000e+00 - mae: 1.4475\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.1932 - accuracy: 0.0000e+00 - mae: 1.3758\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.5303 - accuracy: 0.0000e+00 - mae: 1.4382\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4397 - accuracy: 0.0000e+00 - mae: 1.4592\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1103 - accuracy: 0.0000e+00 - mae: 1.3662\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3437 - accuracy: 0.0000e+00 - mae: 1.4165\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4719 - accuracy: 0.0000e+00 - mae: 1.4674\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2289 - accuracy: 0.0000e+00 - mae: 1.3799\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.4166 - accuracy: 0.0000e+00 - mae: 1.4349\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.1672 - accuracy: 0.0000e+00 - mae: 1.3771\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3243 - accuracy: 0.0000e+00 - mae: 1.4263\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1996 - accuracy: 0.0000e+00 - mae: 1.3746\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.3377 - accuracy: 0.0000e+00 - mae: 1.4072\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.2688 - accuracy: 0.0000e+00 - mae: 1.4045\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.3697 - accuracy: 0.0000e+00 - mae: 1.4244\n",
            "acc Score: 0.351123595505618\n",
            "Kappa Score: 0.18313872800281272\n",
            "\n",
            "--------Fold 5--------\n",
            "\n",
            "Training Word2Vec Model...\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_8 (LSTM)                (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 6s 17ms/step - loss: 68.3004 - accuracy: 0.0000e+00 - mae: 8.0905\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 18.0871 - accuracy: 0.0000e+00 - mae: 3.8538\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 4.1604 - accuracy: 0.0000e+00 - mae: 1.5939\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 4.1598 - accuracy: 0.0000e+00 - mae: 1.5872\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.5673 - accuracy: 0.0000e+00 - mae: 1.4527\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.6369 - accuracy: 0.0000e+00 - mae: 1.4994\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.7450 - accuracy: 0.0000e+00 - mae: 1.5067\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.6843 - accuracy: 0.0000e+00 - mae: 1.4713\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.4976 - accuracy: 0.0000e+00 - mae: 1.4671\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.5700 - accuracy: 0.0000e+00 - mae: 1.4872\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.6463 - accuracy: 0.0000e+00 - mae: 1.4786\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.6855 - accuracy: 0.0000e+00 - mae: 1.4921\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.1678 - accuracy: 0.0000e+00 - mae: 1.3780\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.5630 - accuracy: 0.0000e+00 - mae: 1.4797\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3089 - accuracy: 0.0000e+00 - mae: 1.4272\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.3438 - accuracy: 0.0000e+00 - mae: 1.4282\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.6468 - accuracy: 0.0000e+00 - mae: 1.4879\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4315 - accuracy: 0.0000e+00 - mae: 1.4485\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.0437 - accuracy: 0.0000e+00 - mae: 1.3709\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4192 - accuracy: 0.0000e+00 - mae: 1.4460\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.2892 - accuracy: 0.0000e+00 - mae: 1.4375\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 3.3619 - accuracy: 0.0000e+00 - mae: 1.4097\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4761 - accuracy: 0.0000e+00 - mae: 1.4249\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.6310 - accuracy: 0.0000e+00 - mae: 1.4723\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.1694 - accuracy: 0.0000e+00 - mae: 1.4002\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4824 - accuracy: 0.0000e+00 - mae: 1.4298\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1897 - accuracy: 0.0000e+00 - mae: 1.3914\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3455 - accuracy: 0.0000e+00 - mae: 1.4025\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.2580 - accuracy: 0.0000e+00 - mae: 1.3924\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1759 - accuracy: 0.0000e+00 - mae: 1.3809\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2485 - accuracy: 0.0000e+00 - mae: 1.4065\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2996 - accuracy: 0.0000e+00 - mae: 1.4253\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.3292 - accuracy: 0.0000e+00 - mae: 1.4153\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.2774 - accuracy: 0.0000e+00 - mae: 1.4094\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.1303 - accuracy: 0.0000e+00 - mae: 1.4154\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 2.9586 - accuracy: 0.0000e+00 - mae: 1.3491\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.3351 - accuracy: 0.0000e+00 - mae: 1.4140\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1008 - accuracy: 0.0000e+00 - mae: 1.3614\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.5844 - accuracy: 0.0000e+00 - mae: 1.4510\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2658 - accuracy: 0.0000e+00 - mae: 1.4096\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4807 - accuracy: 0.0000e+00 - mae: 1.4176\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.4130 - accuracy: 0.0000e+00 - mae: 1.4245\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.1232 - accuracy: 0.0000e+00 - mae: 1.3622\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.2271 - accuracy: 0.0000e+00 - mae: 1.3781\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.1376 - accuracy: 0.0000e+00 - mae: 1.3843\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.3272 - accuracy: 0.0000e+00 - mae: 1.4374\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.0553 - accuracy: 0.0000e+00 - mae: 1.3575\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 3.0791 - accuracy: 0.0000e+00 - mae: 1.3863\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.2139 - accuracy: 0.0000e+00 - mae: 1.3865\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 3.1694 - accuracy: 0.0000e+00 - mae: 1.3694\n",
            "acc Score: 0.3089887640449438\n",
            "Kappa Score: 0.12862588795729424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUSc_ZpHOlaT",
        "outputId": "1f9b0a4a-932f-467b-c33b-af5cb124f28f"
      },
      "source": [
        "print(\"Average Kappa score after a 5-fold cross validation: \",np.around(np.array(results).mean(),decimals=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Kappa score after a 5-fold cross validation:  0.1489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klrdtTe0b8R6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtygtsOFPUwG"
      },
      "source": [
        "##**kappa Score**\n",
        "\n",
        "Cohens Kappa is used to distinguish between reliability and validity. It does really good for multi-class problems. It is the quantitative measure of  reliability for two raters, rating for the same thing, and corrected for how often that the raters might agree by chance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EO4tYGYPeQz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}